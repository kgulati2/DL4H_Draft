{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Electronic health records (EHRs) are a digital version of a patient's medical history. They can capture patient encounters and include structured examples such as lab results and medication information as well as unstructured examples such as clinical notes and medical imaging. The modeling of these EHRs is becoming an important topic in both academia as well as industry. Researchers have used the model architecture MiME to reflect an EHR's encounter structure particularly in mapping the relationship between a diagnosis and treatment. They found it outperformed the alternative bag of features approach in prediction tasks like heart failure diagnosis prediction [Choi et al. 2018]. The problem is that not all EHR data contains structured information detailing the relationships between different features. Taking this even further |  claims data generally has no structured information available at all. The underlying question is whether it is possible to outperform the bag of features approach in representing data for prediction tasks.\n",
    "\n",
    "The paper proposed the approach of using the Graph Convolutional Transformer (GCT) |  which is a novel approach that can learn the hidden structure of EHRs while performing prediction tasks [Choi et al. 2020]. It represents EHR data as a graph where the nodes represent medical entities and the edges denote specific relationships between the entities. The GCT model combines graph convolutional networks (GCNs) innovating with the incorporation of a self-attention mechanism as well as the transformer architecture. This enables it to learn embeddings and relationships between EHR entities. Those embeddings can then be used for predictive tasks such as heart failure diagnosis prediction. The proposed method worked extremely well and researchers found that GCT outperforms baseline models in all prediction tasks including graph reconstruction and readmission prediction with both synthetic data as well as a publicly available HER dataset. This shows the potential GCT has in serving as an effective general purpose representation learning algorithm for EHR data. This paper is incredibly important to the research regime of modeling EHR data because it introduced a pioneering approach for analyzing EHRs using graph representation and the GCT model. This method significantly enhances predictive accuracy across various healthcare tasks and offers a promising avenue to leverage HER data and improve patient care."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope of Reproducibility\n",
    "\n",
    "Hypothesis: Learning the hidden structure of EHR data using the Graph Convolution Transformer |  while performing supervised prediction tasks on EHR data will empirically outperform previous approaches (such as bag of features).\n",
    "\n",
    "Experiment: The testing of this hypothesis involves comparing the performance of the Graph Convolutional Transformer (GCT) model against previous approaches like the bag of features method in supervised prediction tasks that use EHR data. The experiment includes preprocessing the EHR data to represent it as graphs for the GCT model and feature vectors for the bag of features method. The models will then be trained and their performance metrics will be evaluated against one another. By comparing the predictive performance of the GCT model against the bag of features method |  the experiment aims to empirically demonstrate whether leveraging the hidden structure of EHR data with the GCT model leads to superior predictive performance compared to traditional approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Source of the data: In order to gain access to the EHR data |  you first need to request access to the eICU dataset from the eICU website. This requires some CITI training as this data is restricted |  non-public data.\n",
    "\n",
    "There are 4 files of data that are taken from this dataset and are as follows:\n",
    "\n",
    "| admissionDx.csv (626859 Lines)| diagnosis.csv (2710673 Lines)| patient.csv (200860 Lines)| treatment.csv (3688746 Lines)|\n",
    "| --- | --- | --- | --- |\n",
    "\n",
    "They contain the following data:\n",
    "\n",
    "| admissionDx.csv | diagnosis.csv | patient.csv | treatment.csv |\n",
    "| --- | --- | --- | --- |\n",
    "| admissiondxid | diagnosisid | patientunitstayid | treatmentid |\n",
    "| patientunitstayid | patientunitstayid | patienthealthsystemstayid | patientunitstayid |\n",
    "| admitdxenteredoffset | activeupondischarge | gender | treatmentoffset |\n",
    "| admitdxpath | diagnosisoffset | age | treatmentstring |\n",
    "| admitdxname | diagnosisstring | hospitalid | activeupondischarge |\n",
    "| admitdxtext | icd9code | wardid |\n",
    "| | diagnosispriority | apacheadmissiondx |\n",
    "| | | admissionheight |\n",
    "| | | hospitaladmittime24 |\n",
    "| | | hospitaladmitoffset |\n",
    "| | | hospitaladmitsource |\n",
    "| | | hospitaldischargeyear |\n",
    "| | | hospitaldischargetime24 |\n",
    "| | | hospitaldischargeoffset |\n",
    "| | | hospitaldischargelocation |\n",
    "| | | hospitaldischargestatus |\n",
    "| | | unittype |\n",
    "| | | unitadmittime24 |\n",
    "| | | unitadmitsource |\n",
    "| | | unitvisitnumber |\n",
    "| | | unitstaytype |\n",
    "| | | admissionweight |\n",
    "| | | dischargeweight |\n",
    "| | | unitdischargetime24 |\n",
    "| | | unitdischargeoffset |\n",
    "| | | unitdischargelocation |\n",
    "| | | unitdischargestatus |\n",
    "| | | uniquepid |\n",
    "| | | ethnicity |\n",
    "\n",
    "In order to make the raw data fit for usage for the purposes of this experiment and generate TFRecords, data preprocessing code was run. This code generated 5 randomly sampled sets of train/validation/test data. This code was provided by the authors of the original paper.\n",
    "\n",
    "Firstly you must create the virtualenv venv_gnn using terminal. Then you will open up the virtual environment and install the right python version, tensorflow, and scikit-learn."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "virtualenv -p /usr/bin/python2.7 venv_gnn\n",
    "source venv_gnn/bin/activate\n",
    "pip install TensorFlow 1.13\n",
    "pip install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then run the following code with the terminal command specifying the paths:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "python process_eicu.py <path to CSV files> <output path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Copyright 2019 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import cPickle as pickle\n",
    "import csv\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class EncounterInfo(object):\n",
    "\n",
    "  def __init__(self, patient_id, encounter_id, encounter_timestamp, expired,\n",
    "               readmission):\n",
    "    self.patient_id = patient_id\n",
    "    self.encounter_id = encounter_id\n",
    "    self.encounter_timestamp = encounter_timestamp\n",
    "    self.expired = expired\n",
    "    self.readmission = readmission\n",
    "    self.dx_ids = []\n",
    "    self.rx_ids = []\n",
    "    self.labs = {}\n",
    "    self.physicals = []\n",
    "    self.treatments = []\n",
    "\n",
    "\n",
    "def process_patient(infile, encounter_dict, hour_threshold=24):\n",
    "  inff = open(infile, 'r')\n",
    "  count = 0\n",
    "  patient_dict = {}\n",
    "  for line in csv.DictReader(inff):\n",
    "    if count % 10000 == 0:\n",
    "      sys.stdout.write('%d\\r' % count)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    patient_id = line['patienthealthsystemstayid']\n",
    "    encounter_id = line['patientunitstayid']\n",
    "    encounter_timestamp = -int(line['hospitaladmitoffset'])\n",
    "    if patient_id not in patient_dict:\n",
    "      patient_dict[patient_id] = []\n",
    "    patient_dict[patient_id].append((encounter_timestamp, encounter_id))\n",
    "  inff.close()\n",
    "  print('')\n",
    "\n",
    "  patient_dict_sorted = {}\n",
    "  for patient_id, time_enc_tuples in patient_dict.iteritems():\n",
    "    patient_dict_sorted[patient_id] = sorted(time_enc_tuples)\n",
    "\n",
    "  enc_readmission_dict = {}\n",
    "  for patient_id, time_enc_tuples in patient_dict_sorted.iteritems():\n",
    "    for time_enc_tuple in time_enc_tuples[:-1]:\n",
    "      enc_id = time_enc_tuple[1]\n",
    "      enc_readmission_dict[enc_id] = True\n",
    "    last_enc_id = time_enc_tuples[-1][1]\n",
    "    enc_readmission_dict[last_enc_id] = False\n",
    "\n",
    "  inff = open(infile, 'r')\n",
    "  count = 0\n",
    "  for line in csv.DictReader(inff):\n",
    "    if count % 10000 == 0:\n",
    "      sys.stdout.write('%d\\r' % count)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    patient_id = line['patienthealthsystemstayid']\n",
    "    encounter_id = line['patientunitstayid']\n",
    "    encounter_timestamp = -int(line['hospitaladmitoffset'])\n",
    "    discharge_status = line['unitdischargestatus']\n",
    "    duration_minute = float(line['unitdischargeoffset'])\n",
    "    expired = True if discharge_status == 'Expired' else False\n",
    "    readmission = enc_readmission_dict[encounter_id]\n",
    "\n",
    "    if duration_minute > 60. * hour_threshold:\n",
    "      continue\n",
    "\n",
    "    ei = EncounterInfo(patient_id, encounter_id, encounter_timestamp, expired,\n",
    "                       readmission)\n",
    "    if encounter_id in encounter_dict:\n",
    "      print('Duplicate encounter ID!!')\n",
    "      sys.exit(0)\n",
    "    encounter_dict[encounter_id] = ei\n",
    "    count += 1\n",
    "\n",
    "  inff.close()\n",
    "  print('')\n",
    "\n",
    "  return encounter_dict\n",
    "\n",
    "\n",
    "def process_admission_dx(infile, encounter_dict):\n",
    "  inff = open(infile, 'r')\n",
    "  count = 0\n",
    "  missing_eid = 0\n",
    "  for line in csv.DictReader(inff):\n",
    "    if count % 10000 == 0:\n",
    "      sys.stdout.write('%d\\r' % count)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    encounter_id = line['patientunitstayid']\n",
    "    dx_id = line['admitdxpath'].lower()\n",
    "\n",
    "    if encounter_id not in encounter_dict:\n",
    "      missing_eid += 1\n",
    "      continue\n",
    "    encounter_dict[encounter_id].dx_ids.append(dx_id)\n",
    "    count += 1\n",
    "  inff.close()\n",
    "  print('')\n",
    "  print('Admission Diagnosis without Encounter ID: %d' % missing_eid)\n",
    "\n",
    "  return encounter_dict\n",
    "\n",
    "\n",
    "def process_diagnosis(infile, encounter_dict):\n",
    "  inff = open(infile, 'r')\n",
    "  count = 0\n",
    "  missing_eid = 0\n",
    "  for line in csv.DictReader(inff):\n",
    "    if count % 10000 == 0:\n",
    "      sys.stdout.write('%d\\r' % count)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    encounter_id = line['patientunitstayid']\n",
    "    dx_id = line['diagnosisstring'].lower()\n",
    "\n",
    "    if encounter_id not in encounter_dict:\n",
    "      missing_eid += 1\n",
    "      continue\n",
    "    encounter_dict[encounter_id].dx_ids.append(dx_id)\n",
    "    count += 1\n",
    "  inff.close()\n",
    "  print('')\n",
    "  print('Diagnosis without Encounter ID: %d' % missing_eid)\n",
    "\n",
    "  return encounter_dict\n",
    "\n",
    "\n",
    "def process_treatment(infile, encounter_dict):\n",
    "  inff = open(infile, 'r')\n",
    "  count = 0\n",
    "  missing_eid = 0\n",
    "\n",
    "  for line in csv.DictReader(inff):\n",
    "    if count % 10000 == 0:\n",
    "      sys.stdout.write('%d\\r' % count)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    encounter_id = line['patientunitstayid']\n",
    "    treatment_id = line['treatmentstring'].lower()\n",
    "\n",
    "    if encounter_id not in encounter_dict:\n",
    "      missing_eid += 1\n",
    "      continue\n",
    "    encounter_dict[encounter_id].treatments.append(treatment_id)\n",
    "    count += 1\n",
    "  inff.close()\n",
    "  print('')\n",
    "  print('Treatment without Encounter ID: %d' % missing_eid)\n",
    "  print('Accepted treatments: %d' % count)\n",
    "\n",
    "  return encounter_dict\n",
    "\n",
    "\n",
    "def build_seqex(enc_dict,\n",
    "                skip_duplicate=False,\n",
    "                min_num_codes=1,\n",
    "                max_num_codes=50):\n",
    "  key_list = []\n",
    "  seqex_list = []\n",
    "  dx_str2int = {}\n",
    "  treat_str2int = {}\n",
    "  num_cut = 0\n",
    "  num_duplicate = 0\n",
    "  count = 0\n",
    "  num_dx_ids = 0\n",
    "  num_treatments = 0\n",
    "  num_unique_dx_ids = 0\n",
    "  num_unique_treatments = 0\n",
    "  min_dx_cut = 0\n",
    "  min_treatment_cut = 0\n",
    "  max_dx_cut = 0\n",
    "  max_treatment_cut = 0\n",
    "  num_expired = 0\n",
    "  num_readmission = 0\n",
    "\n",
    "  for _, enc in enc_dict.iteritems():\n",
    "    if skip_duplicate:\n",
    "      if (len(enc.dx_ids) > len(set(enc.dx_ids)) or\n",
    "          len(enc.treatments) > len(set(enc.treatments))):\n",
    "        num_duplicate += 1\n",
    "        continue\n",
    "\n",
    "    if len(set(enc.dx_ids)) < min_num_codes:\n",
    "      min_dx_cut += 1\n",
    "      continue\n",
    "\n",
    "    if len(set(enc.treatments)) < min_num_codes:\n",
    "      min_treatment_cut += 1\n",
    "      continue\n",
    "\n",
    "    if len(set(enc.dx_ids)) > max_num_codes:\n",
    "      max_dx_cut += 1\n",
    "      continue\n",
    "\n",
    "    if len(set(enc.treatments)) > max_num_codes:\n",
    "      max_treatment_cut += 1\n",
    "      continue\n",
    "\n",
    "    count += 1\n",
    "    num_dx_ids += len(enc.dx_ids)\n",
    "    num_treatments += len(enc.treatments)\n",
    "    num_unique_dx_ids += len(set(enc.dx_ids))\n",
    "    num_unique_treatments += len(set(enc.treatments))\n",
    "\n",
    "    for dx_id in enc.dx_ids:\n",
    "      if dx_id not in dx_str2int:\n",
    "        dx_str2int[dx_id] = len(dx_str2int)\n",
    "\n",
    "    for treat_id in enc.treatments:\n",
    "      if treat_id not in treat_str2int:\n",
    "        treat_str2int[treat_id] = len(treat_str2int)\n",
    "\n",
    "    seqex = tf.train.SequenceExample()\n",
    "    seqex.context.feature['patientId'].bytes_list.value.append(enc.patient_id +\n",
    "                                                               ':' +\n",
    "                                                               enc.encounter_id)\n",
    "    if enc.expired:\n",
    "      seqex.context.feature['label.expired'].int64_list.value.append(1)\n",
    "      num_expired += 1\n",
    "    else:\n",
    "      seqex.context.feature['label.expired'].int64_list.value.append(0)\n",
    "\n",
    "    if enc.readmission:\n",
    "      seqex.context.feature['label.readmission'].int64_list.value.append(1)\n",
    "      num_readmission += 1\n",
    "    else:\n",
    "      seqex.context.feature['label.readmission'].int64_list.value.append(0)\n",
    "\n",
    "    dx_ids = seqex.feature_lists.feature_list['dx_ids']\n",
    "    dx_ids.feature.add().bytes_list.value.extend(list(set(enc.dx_ids)))\n",
    "\n",
    "    dx_int_list = [dx_str2int[item] for item in list(set(enc.dx_ids))]\n",
    "    dx_ints = seqex.feature_lists.feature_list['dx_ints']\n",
    "    dx_ints.feature.add().int64_list.value.extend(dx_int_list)\n",
    "\n",
    "    proc_ids = seqex.feature_lists.feature_list['proc_ids']\n",
    "    proc_ids.feature.add().bytes_list.value.extend(list(set(enc.treatments)))\n",
    "\n",
    "    proc_int_list = [treat_str2int[item] for item in list(set(enc.treatments))]\n",
    "    proc_ints = seqex.feature_lists.feature_list['proc_ints']\n",
    "    proc_ints.feature.add().int64_list.value.extend(proc_int_list)\n",
    "\n",
    "    seqex_list.append(seqex)\n",
    "    key = seqex.context.feature['patientId'].bytes_list.value[0]\n",
    "    key_list.append(key)\n",
    "\n",
    "  print('Filtered encounters due to duplicate codes: %d' % num_duplicate)\n",
    "  print('Filtered encounters due to thresholding: %d' % num_cut)\n",
    "  print('Average num_dx_ids: %f' % (num_dx_ids / count))\n",
    "  print('Average num_treatments: %f' % (num_treatments / count))\n",
    "  print('Average num_unique_dx_ids: %f' % (num_unique_dx_ids / count))\n",
    "  print('Average num_unique_treatments: %f' % (num_unique_treatments / count))\n",
    "  print('Min dx cut: %d' % min_dx_cut)\n",
    "  print('Min treatment cut: %d' % min_treatment_cut)\n",
    "  print('Max dx cut: %d' % max_dx_cut)\n",
    "  print('Max treatment cut: %d' % max_treatment_cut)\n",
    "  print('Number of expired: %d' % num_expired)\n",
    "  print('Number of readmission: %d' % num_readmission)\n",
    "\n",
    "  return key_list, seqex_list, dx_str2int, treat_str2int\n",
    "\n",
    "\n",
    "def select_train_valid_test(key_list, random_seed=1234):\n",
    "  key_train, key_temp = ms.train_test_split(\n",
    "      key_list, test_size=0.2, random_state=random_seed)\n",
    "  key_valid, key_test = ms.train_test_split(\n",
    "      key_temp, test_size=0.5, random_state=random_seed)\n",
    "  return key_train, key_valid, key_test\n",
    "\n",
    "\n",
    "def count_conditional_prob_dp(seqex_list, output_path, train_key_set=None):\n",
    "  dx_freqs = {}\n",
    "  proc_freqs = {}\n",
    "  dp_freqs = {}\n",
    "  total_visit = 0\n",
    "  for seqex in seqex_list:\n",
    "    if total_visit % 1000 == 0:\n",
    "      sys.stdout.write('Visit count: %d\\r' % total_visit)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    key = seqex.context.feature['patientId'].bytes_list.value[0]\n",
    "    if (train_key_set is not None and key not in train_key_set):\n",
    "      total_visit += 1\n",
    "      continue\n",
    "\n",
    "    dx_ids = seqex.feature_lists.feature_list['dx_ids'].feature[\n",
    "        0].bytes_list.value\n",
    "    proc_ids = seqex.feature_lists.feature_list['proc_ids'].feature[\n",
    "        0].bytes_list.value\n",
    "\n",
    "    for dx in dx_ids:\n",
    "      if dx not in dx_freqs:\n",
    "        dx_freqs[dx] = 0\n",
    "      dx_freqs[dx] += 1\n",
    "\n",
    "    for proc in proc_ids:\n",
    "      if proc not in proc_freqs:\n",
    "        proc_freqs[proc] = 0\n",
    "      proc_freqs[proc] += 1\n",
    "\n",
    "    for dx in dx_ids:\n",
    "      for proc in proc_ids:\n",
    "        dp = dx + ',' + proc\n",
    "        if dp not in dp_freqs:\n",
    "          dp_freqs[dp] = 0\n",
    "        dp_freqs[dp] += 1\n",
    "\n",
    "    total_visit += 1\n",
    "\n",
    "  dx_probs = dict([(k, v / float(total_visit)) for k, v in dx_freqs.iteritems()\n",
    "                  ])\n",
    "  proc_probs = dict([\n",
    "      (k, v / float(total_visit)) for k, v in proc_freqs.iteritems()\n",
    "  ])\n",
    "  dp_probs = dict([(k, v / float(total_visit)) for k, v in dp_freqs.iteritems()\n",
    "                  ])\n",
    "\n",
    "  dp_cond_probs = {}\n",
    "  pd_cond_probs = {}\n",
    "  for dx, dx_prob in dx_probs.iteritems():\n",
    "    for proc, proc_prob in proc_probs.iteritems():\n",
    "      dp = dx + ',' + proc\n",
    "      pd = proc + ',' + dx\n",
    "      if dp in dp_probs:\n",
    "        dp_cond_probs[dp] = dp_probs[dp] / dx_prob\n",
    "        pd_cond_probs[pd] = dp_probs[dp] / proc_prob\n",
    "      else:\n",
    "        dp_cond_probs[dp] = 0.0\n",
    "        pd_cond_probs[pd] = 0.0\n",
    "\n",
    "  pickle.dump(dx_probs, open(output_path + '/dx_probs.empirical.p', 'wb'), -1)\n",
    "  pickle.dump(proc_probs, open(output_path + '/proc_probs.empirical.p', 'wb'),\n",
    "              -1)\n",
    "  pickle.dump(dp_probs, open(output_path + '/dp_probs.empirical.p', 'wb'), -1)\n",
    "  pickle.dump(dp_cond_probs,\n",
    "              open(output_path + '/dp_cond_probs.empirical.p', 'wb'), -1)\n",
    "  pickle.dump(pd_cond_probs,\n",
    "              open(output_path + '/pd_cond_probs.empirical.p', 'wb'), -1)\n",
    "\n",
    "\n",
    "def add_sparse_prior_guide_dp(seqex_list,\n",
    "                              stats_path,\n",
    "                              key_set=None,\n",
    "                              max_num_codes=50):\n",
    "  print('Loading conditional probabilities.')\n",
    "  dp_cond_probs = pickle.load(\n",
    "      open(stats_path + '/dp_cond_probs.empirical.p', 'rb'))\n",
    "  pd_cond_probs = pickle.load(\n",
    "      open(stats_path + '/pd_cond_probs.empirical.p', 'rb'))\n",
    "\n",
    "  print('Adding prior guide.')\n",
    "  total_visit = 0\n",
    "  new_seqex_list = []\n",
    "  for seqex in seqex_list:\n",
    "    if total_visit % 1000 == 0:\n",
    "      sys.stdout.write('Visit count: %d\\r' % total_visit)\n",
    "      sys.stdout.flush()\n",
    "\n",
    "    key = seqex.context.feature['patientId'].bytes_list.value[0]\n",
    "    if (key_set is not None and key not in key_set):\n",
    "      total_visit += 1\n",
    "      continue\n",
    "\n",
    "    dx_ids = seqex.feature_lists.feature_list['dx_ids'].feature[\n",
    "        0].bytes_list.value\n",
    "    proc_ids = seqex.feature_lists.feature_list['proc_ids'].feature[\n",
    "        0].bytes_list.value\n",
    "\n",
    "    indices = []\n",
    "    values = []\n",
    "    for i, dx in enumerate(dx_ids):\n",
    "      for j, proc in enumerate(proc_ids):\n",
    "        dp = dx + ',' + proc\n",
    "        indices.append((i, max_num_codes + j))\n",
    "        prob = 0.0 if dp not in dp_cond_probs else dp_cond_probs[dp]\n",
    "        values.append(prob)\n",
    "\n",
    "    for i, proc in enumerate(proc_ids):\n",
    "      for j, dx in enumerate(dx_ids):\n",
    "        pd = proc + ',' + dx\n",
    "        indices.append((max_num_codes + i, j))\n",
    "        prob = 0.0 if pd not in pd_cond_probs else pd_cond_probs[pd]\n",
    "        values.append(prob)\n",
    "\n",
    "    indices = list(np.array(indices).reshape([-1]))\n",
    "    indices_feature = seqex.feature_lists.feature_list['prior_indices']\n",
    "    indices_feature.feature.add().int64_list.value.extend(indices)\n",
    "    values_feature = seqex.feature_lists.feature_list['prior_values']\n",
    "    values_feature.feature.add().float_list.value.extend(values)\n",
    "\n",
    "    new_seqex_list.append(seqex)\n",
    "    total_visit += 1\n",
    "\n",
    "  return new_seqex_list\n",
    "\n",
    "\n",
    "\"\"\"Set <input_path> to where the raw eICU CSV files are located.\n",
    "Set <output_path> to where you want the output files to be.\n",
    "\"\"\"\n",
    "def main(argv):\n",
    "  input_path = argv[1]\n",
    "  output_path = argv[2]\n",
    "  num_fold = 5\n",
    "\n",
    "  patient_file = input_path + '/patient.csv'\n",
    "  admission_dx_file = input_path + '/admissionDx.csv'\n",
    "  diagnosis_file = input_path + '/diagnosis.csv'\n",
    "  treatment_file = input_path + '/treatment.csv'\n",
    "\n",
    "  encounter_dict = {}\n",
    "  print('Processing patient.csv')\n",
    "  encounter_dict = process_patient(\n",
    "      patient_file, encounter_dict, hour_threshold=24)\n",
    "  print('Processing admission diagnosis.csv')\n",
    "  encounter_dict = process_admission_dx(admission_dx_file, encounter_dict)\n",
    "  print('Processing diagnosis.csv')\n",
    "  encounter_dict = process_diagnosis(diagnosis_file, encounter_dict)\n",
    "  print('Processing treatment.csv')\n",
    "  encounter_dict = process_treatment(treatment_file, encounter_dict)\n",
    "\n",
    "  key_list, seqex_list, dx_map, proc_map = build_seqex(\n",
    "      encounter_dict, skip_duplicate=False, min_num_codes=1, max_num_codes=50)\n",
    "\n",
    "  pickle.dump(dx_map, open(output_path + '/dx_map.p', 'wb'), -1)\n",
    "  pickle.dump(proc_map, open(output_path + '/proc_map.p', 'wb'), -1)\n",
    "\n",
    "  for i in range(num_fold):\n",
    "    fold_path = output_path + '/fold_' + str(i)\n",
    "    stats_path = fold_path + '/train_stats'\n",
    "    os.makedirs(stats_path)\n",
    "\n",
    "    key_train, key_valid, key_test = select_train_valid_test(\n",
    "        key_list, random_seed=i)\n",
    "\n",
    "    count_conditional_prob_dp(seqex_list, stats_path, set(key_train))\n",
    "    train_seqex = add_sparse_prior_guide_dp(\n",
    "        seqex_list, stats_path, set(key_train), max_num_codes=50)\n",
    "    validation_seqex = add_sparse_prior_guide_dp(\n",
    "        seqex_list, stats_path, set(key_valid), max_num_codes=50)\n",
    "    test_seqex = add_sparse_prior_guide_dp(\n",
    "        seqex_list, stats_path, set(key_test), max_num_codes=50)\n",
    "\n",
    "    with tf.io.TFRecordWriter(fold_path + '/train.tfrecord') as writer:\n",
    "      for seqex in train_seqex:\n",
    "        writer.write(seqex.SerializeToString())\n",
    "\n",
    "    with tf.io.TFRecordWriter(fold_path + '/validation.tfrecord') as writer:\n",
    "      for seqex in validation_seqex:\n",
    "        writer.write(seqex.SerializeToString())\n",
    "\n",
    "    with tf.io.TFRecordWriter(fold_path + '/test.tfrecord') as writer:\n",
    "      for seqex in test_seqex:\n",
    "        writer.write(seqex.SerializeToString())\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main(sys.argv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate 5 randomly sampled sets of train, validation, and test data.\n",
    "\n",
    "### Model\n",
    "\n",
    "Now we take a look at the model that is being implemented for this EHR data. The approach of this model was to see if there was a more accurate way to predict against EHR data than the current \"bag of features\" methodology. EHR data is layered, meaning that their is a graphical connection between decisions on perscriptions, and the bag of features method does not account for this.\n",
    "\n",
    "By using a Graphical Convolutional Transformer, we can learn about the hidden encounter structure. It uses the characteristics of the EHR data, along with the conditional probabilities between features. \n",
    "\n",
    "We run the below code to define the model and transformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Copyright 2019 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "class FeatureEmbedder(object):\n",
    "  \"\"\"This class is used to convert SparseTensor inputs to dense Tensors.\n",
    "\n",
    "  This class is used to convert raw features to their vector representations.\n",
    "  It takes in a dictionary, where the key is the name of a feature (e.g.\n",
    "  diagnosis_id) and the value is a SparseTensor of integers (i.e. lookup IDs),\n",
    "  then retrieves corresponding vector representations using tf.embedding.lookup.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, vocab_sizes, feature_keys, embedding_size):\n",
    "    \"\"\"Init function.\n",
    "\n",
    "    Args:\n",
    "      vocab_sizes: A dictionary of vocabularize sizes for each feature.\n",
    "      feature_keys: A list of feature names you want to use.\n",
    "      embedding_size: The dimension size of the feature representation vector.\n",
    "    \"\"\"\n",
    "    self._params = {}\n",
    "    self._feature_keys = feature_keys\n",
    "    self._vocab_sizes = vocab_sizes\n",
    "    dummy_emb = tf.zeros([1, embedding_size], dtype=tf.float32)\n",
    "\n",
    "    for feature_key in feature_keys:\n",
    "      vocab_size = self._vocab_sizes[feature_key]\n",
    "      emb = tf.get_variable(\n",
    "          feature_key, shape=(vocab_size, embedding_size), dtype=tf.float32)\n",
    "      self._params[feature_key] = tf.concat([emb, dummy_emb], axis=0)\n",
    "\n",
    "    self._params['visit'] = tf.get_variable(\n",
    "        'visit', shape=(1, embedding_size), dtype=tf.float32)\n",
    "\n",
    "  def lookup(self, feature_map, max_num_codes):\n",
    "    \"\"\"Look-up function.\n",
    "\n",
    "    This function converts the SparseTensor of integers to a dense Tensor of\n",
    "    tf.float32.\n",
    "\n",
    "    Args:\n",
    "      feature_map: A dictionary of SparseTensors for each feature.\n",
    "      max_num_codes: The maximum number of how many feature there can be inside\n",
    "        a single visit, per feature. For example, if this is set to 50, then we\n",
    "        are assuming there can be up to 50 diagnosis codes, 50 treatment codes,\n",
    "        and 50 lab codes. This will be used for creating the prior matrix.\n",
    "\n",
    "    Returns:\n",
    "      embeddings: A dictionary of dense representation Tensors for each feature.\n",
    "      masks: A dictionary of dense float32 Tensors for each feature, that will\n",
    "        be used as a mask in the downstream tasks.\n",
    "    \"\"\"\n",
    "    masks = {}\n",
    "    embeddings = {}\n",
    "    for key in self._feature_keys:\n",
    "      if max_num_codes > 0:\n",
    "        feature = tf.SparseTensor(\n",
    "            indices=feature_map[key].indices,\n",
    "            values=feature_map[key].values,\n",
    "            dense_shape=[\n",
    "                feature_map[key].dense_shape[0],\n",
    "                feature_map[key].dense_shape[1], max_num_codes\n",
    "            ])\n",
    "      else:\n",
    "        feature = feature_map[key]\n",
    "      feature_ids = tf.sparse.to_dense(\n",
    "          feature, default_value=self._vocab_sizes[key])\n",
    "      feature_ids = tf.squeeze(feature_ids, axis=1)\n",
    "      embeddings[key] = tf.nn.embedding_lookup(self._params[key], feature_ids)\n",
    "\n",
    "      mask = tf.SparseTensor(\n",
    "          indices=feature.indices,\n",
    "          values=tf.ones(tf.shape(feature.values)),\n",
    "          dense_shape=feature.dense_shape)\n",
    "      masks[key] = tf.squeeze(tf.sparse.to_dense(mask), axis=1)\n",
    "\n",
    "    batch_size = tf.shape(embeddings.values()[0])[0]\n",
    "    embeddings['visit'] = tf.tile(self._params['visit'][None, :, :],\n",
    "                                  [batch_size, 1, 1])\n",
    "\n",
    "    masks['visit'] = tf.ones(batch_size)[:, None]\n",
    "\n",
    "    return embeddings, masks\n",
    "\n",
    "\n",
    "class GraphConvolutionalTransformer(tf.keras.layers.Layer):\n",
    "  \"\"\"Graph Convolutional Transformer class.\n",
    "\n",
    "  This is an implementation of Graph Convolutional Transformer. With a proper\n",
    "  set of options, it can be used as a vanilla Transformer.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               embedding_size=128,\n",
    "               num_transformer_stack=3,\n",
    "               num_feedforward=2,\n",
    "               num_attention_heads=1,\n",
    "               ffn_dropout=0.1,\n",
    "               attention_normalizer='softmax',\n",
    "               multihead_attention_aggregation='concat',\n",
    "               directed_attention=False,\n",
    "               use_inf_mask=True,\n",
    "               use_prior=True,\n",
    "               **kwargs):\n",
    "    \"\"\"Init function.\n",
    "\n",
    "    Args:\n",
    "      embedding_size: The size of the dimension for hidden layers.\n",
    "      num_transformer_stack: The number of Transformer blocks.\n",
    "      num_feedforward: The number of layers in the feedforward part of\n",
    "        Transformer.\n",
    "      num_attention_heads: The number of attention heads.\n",
    "      ffn_dropout: Dropout rate used inside the feedforward part.\n",
    "      attention_normalizer: Use either 'softmax' or 'sigmoid' to normalize the\n",
    "        attention values.\n",
    "      multihead_attention_aggregation: Use either 'concat' or 'sum' to handle\n",
    "        the outputs from multiple attention heads.\n",
    "      directed_attention: Decide whether you want to use the unidirectional\n",
    "        attention, where information accumulates inside the dummy visit node.\n",
    "      use_inf_mask: Decide whether you want to use the guide matrix. Currently\n",
    "        unused.\n",
    "      use_prior: Decide whether you want to use the conditional probablility\n",
    "        information. Currently unused.\n",
    "      **kwargs: Other arguments to tf.keras.layers.Layer init.\n",
    "    \"\"\"\n",
    "\n",
    "    super(GraphConvolutionalTransformer, self).__init__(**kwargs)\n",
    "    self._hidden_size = embedding_size\n",
    "    self._num_stack = num_transformer_stack\n",
    "    self._num_feedforward = num_feedforward\n",
    "    self._num_heads = num_attention_heads\n",
    "    self._ffn_dropout = ffn_dropout\n",
    "    self._attention_normalizer = attention_normalizer\n",
    "    self._multihead_aggregation = multihead_attention_aggregation\n",
    "    self._directed_attention = directed_attention\n",
    "    self._use_inf_mask = use_inf_mask\n",
    "    self._use_prior = use_prior\n",
    "\n",
    "    self._layers = {}\n",
    "    self._layers['Q'] = []\n",
    "    self._layers['K'] = []\n",
    "    self._layers['V'] = []\n",
    "    self._layers['ffn'] = []\n",
    "    self._layers['head_agg'] = []\n",
    "\n",
    "    for i in range(self._num_stack):\n",
    "      self._layers['Q'].append(\n",
    "          tf.keras.layers.Dense(\n",
    "              self._hidden_size * self._num_heads, use_bias=False))\n",
    "      self._layers['K'].append(\n",
    "          tf.keras.layers.Dense(\n",
    "              self._hidden_size * self._num_heads, use_bias=False))\n",
    "      self._layers['V'].append(\n",
    "          tf.keras.layers.Dense(\n",
    "              self._hidden_size * self._num_heads, use_bias=False))\n",
    "\n",
    "      if self._multihead_aggregation == 'concat':\n",
    "        self._layers['head_agg'].append(\n",
    "            tf.keras.layers.Dense(self._hidden_size, use_bias=False))\n",
    "\n",
    "      self._layers['ffn'].append([])\n",
    "      # Don't need relu for the last feedforward.\n",
    "      for _ in range(self._num_feedforward - 1):\n",
    "        self._layers['ffn'][i].append(\n",
    "            tf.keras.layers.Dense(self._hidden_size, activation='relu'))\n",
    "      self._layers['ffn'][i].append(tf.keras.layers.Dense(self._hidden_size))\n",
    "\n",
    "  def feedforward(self, features, stack_index, training=None):\n",
    "    \"\"\"Feedforward component of Transformer.\n",
    "\n",
    "    Args:\n",
    "      features: 3D float Tensor of size (batch_size, num_features,\n",
    "        embedding_size). This is the input embedding to GCT.\n",
    "      stack_index: An integer to indicate which Transformer block we are in.\n",
    "      training: Whether to run in training or eval mode.\n",
    "\n",
    "    Returns:\n",
    "      Latent representations derived from this feedforward network.\n",
    "    \"\"\"\n",
    "    for i in range(self._num_feedforward):\n",
    "      features = self._layers['ffn'][stack_index][i](features)\n",
    "      if training:\n",
    "        features = tf.nn.dropout(features, rate=self._ffn_dropout)\n",
    "\n",
    "    return features\n",
    "\n",
    "  def qk_op(self,\n",
    "            features,\n",
    "            stack_index,\n",
    "            batch_size,\n",
    "            num_codes,\n",
    "            attention_mask,\n",
    "            inf_mask=None,\n",
    "            directed_mask=None):\n",
    "    \"\"\"Attention generation part of Transformer.\n",
    "\n",
    "    Args:\n",
    "      features: 3D float Tensor of size (batch_size, num_features,\n",
    "        embedding_size). This is the input embedding to GCT.\n",
    "      stack_index: An integer to indicate which Transformer block we are in.\n",
    "      batch_size: The size of the mini batch.\n",
    "      num_codes: The number of features (i.e. codes) given as input.\n",
    "      attention_mask: A Tensor for suppressing the attention on the padded\n",
    "        tokens.\n",
    "      inf_mask: The guide matrix to suppress the attention values to zeros for\n",
    "        certain parts of the attention matrix (e.g. diagnosis codes cannot\n",
    "        attend to other diagnosis codes).\n",
    "      directed_mask: If the user wants to only use the upper-triangle of the\n",
    "        attention for uni-directional attention flow, we use this strictly lower\n",
    "        triangular matrix filled with infinity.\n",
    "\n",
    "    Returns:\n",
    "      The attention distribution derived from the QK operation.\n",
    "    \"\"\"\n",
    "\n",
    "    q = self._layers['Q'][stack_index](features)\n",
    "    q = tf.reshape(q,\n",
    "                   [batch_size, num_codes, self._hidden_size, self._num_heads])\n",
    "\n",
    "    k = self._layers['K'][stack_index](features)\n",
    "    k = tf.reshape(k,\n",
    "                   [batch_size, num_codes, self._hidden_size, self._num_heads])\n",
    "\n",
    "    # Need to transpose q and k to (2, 0, 1)\n",
    "    q = tf.transpose(q, perm=[0, 3, 1, 2])\n",
    "    k = tf.transpose(k, perm=[0, 3, 2, 1])\n",
    "    pre_softmax = tf.matmul(q, k) / tf.sqrt(\n",
    "        tf.cast(self._hidden_size, tf.float32))\n",
    "\n",
    "    pre_softmax -= attention_mask[:, None, None, :]\n",
    "\n",
    "    if inf_mask is not None:\n",
    "      pre_softmax -= inf_mask[:, None, :, :]\n",
    "\n",
    "    if directed_mask is not None:\n",
    "      pre_softmax -= directed_mask\n",
    "\n",
    "    if self._attention_normalizer == 'softmax':\n",
    "      attention = tf.nn.softmax(pre_softmax, axis=3)\n",
    "    else:\n",
    "      attention = tf.nn.sigmoid(pre_softmax)\n",
    "    return attention\n",
    "\n",
    "  def call(self, features, masks, guide=None, prior_guide=None, training=None):\n",
    "    \"\"\"This function transforms the input embeddings.\n",
    "\n",
    "    This function converts the SparseTensor of integers to a dense Tensor of\n",
    "    tf.float32.\n",
    "\n",
    "    Args:\n",
    "      features: 3D float Tensor of size (batch_size, num_features,\n",
    "        embedding_size). This is the input embedding to GCT.\n",
    "      masks: 3D float Tensor of size (batch_size, num_features, 1). This holds\n",
    "        binary values to indicate which parts are padded and which are not.\n",
    "      guide: 3D float Tensor of size (batch_size, num_features, num_features).\n",
    "        This is the guide matrix.\n",
    "      prior_guide: 3D float Tensor of size (batch_size, num_features,\n",
    "        num_features). This is the conditional probability matrix.\n",
    "      training: Whether to run in training or eval mode.\n",
    "\n",
    "    Returns:\n",
    "      features: The final layer of GCT.\n",
    "      attentions: List of attention values from all layers of GCT. This will be\n",
    "        used later to regularize the self-attention process.\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size = tf.shape(features)[0]\n",
    "    num_codes = tf.shape(features)[1]\n",
    "\n",
    "    # Use the given masks to create a negative infinity Tensor to suppress the\n",
    "    # attention weights of the padded tokens. Note that the given masks has\n",
    "    # the shape (batch_size, num_codes, 1), so we remove the last dimension\n",
    "    # during the process.\n",
    "    mask_idx = tf.cast(tf.where(tf.equal(masks[:, :, 0], 0.)), tf.int32)\n",
    "    mask_matrix = tf.fill([tf.shape(mask_idx)[0]], tf.float32.max)\n",
    "    attention_mask = tf.scatter_nd(\n",
    "        indices=mask_idx, updates=mask_matrix, shape=tf.shape(masks[:, :, 0]))\n",
    "\n",
    "    inf_mask = None\n",
    "    if self._use_inf_mask:\n",
    "      guide_idx = tf.cast(tf.where(tf.equal(guide, 0.)), tf.int32)\n",
    "      inf_matrix = tf.fill([tf.shape(guide_idx)[0]], tf.float32.max)\n",
    "      inf_mask = tf.scatter_nd(\n",
    "          indices=guide_idx, updates=inf_matrix, shape=tf.shape(guide))\n",
    "\n",
    "    directed_mask = None\n",
    "    if self._directed_attention:\n",
    "      inf_matrix = tf.fill([num_codes, num_codes], tf.float32.max)\n",
    "      inf_matrix = tf.matrix_set_diag(inf_matrix, tf.zeros(num_codes))\n",
    "      directed_mask = tf.matrix_band_part(inf_matrix, -1, 0)[None, None, :, :]\n",
    "\n",
    "    attention = None\n",
    "    attentions = []\n",
    "    for i in range(self._num_stack):\n",
    "      features = masks * features\n",
    "\n",
    "      if self._use_prior and i == 0:\n",
    "        attention = tf.tile(prior_guide[:, None, :, :],\n",
    "                            [1, self._num_heads, 1, 1])\n",
    "      else:\n",
    "        attention = self.qk_op(features, i, batch_size, num_codes,\n",
    "                               attention_mask, inf_mask, directed_mask)\n",
    "\n",
    "      attentions.append(attention)\n",
    "\n",
    "      v = self._layers['V'][i](features)\n",
    "      v = tf.reshape(\n",
    "          v, [batch_size, num_codes, self._hidden_size, self._num_heads])\n",
    "      v = tf.transpose(v, perm=[0, 3, 1, 2])\n",
    "      # post_attention is (batch, num_heads, num_codes, hidden_size)\n",
    "      post_attention = tf.matmul(attention, v)\n",
    "\n",
    "      if self._num_heads == 1:\n",
    "        post_attention = tf.squeeze(post_attention, axis=1)\n",
    "      elif self._multihead_aggregation == 'concat':\n",
    "        # post_attention is (batch, num_codes, num_heads, hidden_size)\n",
    "        post_attention = tf.transpose(post_attention, perm=[0, 2, 1, 3])\n",
    "        # post_attention is (batch, num_codes, num_heads*hidden_size)\n",
    "        post_attention = tf.reshape(post_attention, [batch_size, num_codes, -1])\n",
    "        # post attention is (batch, num_codes, hidden_size)\n",
    "        post_attention = self._layers['head_agg'][i](post_attention)\n",
    "      else:\n",
    "        post_attention = tf.reduce_sum(post_attention, axis=1)\n",
    "\n",
    "      # Residual connection + layer normalization\n",
    "      post_attention += features\n",
    "      post_attention = tf.contrib.layers.layer_norm(\n",
    "          post_attention, begin_norm_axis=2)\n",
    "\n",
    "      # Feedforward component + residual connection + layer normalization\n",
    "      post_ffn = self.feedforward(post_attention, i, training)\n",
    "      post_ffn += post_attention\n",
    "      post_ffn = tf.contrib.layers.layer_norm(post_ffn, begin_norm_axis=2)\n",
    "\n",
    "      features = post_ffn\n",
    "\n",
    "    return features * masks, attentions\n",
    "\n",
    "\n",
    "def create_matrix_vdpl(features, mask, use_prior, use_inf_mask, max_num_codes,\n",
    "                       prior_scalar):\n",
    "  \"\"\"Creates guide matrix and prior matrix when feature_set='vdpl'.\n",
    "\n",
    "  This function creates the guide matrix and the prior matrix when visits\n",
    "  include diagnosis codes, treatment codes, and lab codes.\n",
    "\n",
    "  Args:\n",
    "    features: A dictionary of SparseTensors for each feature.\n",
    "    mask: 3D float Tensor of size (batch_size, num_features, 1). This holds\n",
    "      binary values to indicate which parts are padded and which are not.\n",
    "    use_prior: Whether to create the prior matrix.\n",
    "    use_inf_mask : Whether to create the guide matrix.\n",
    "    max_num_codes: The maximum number of how many feature there can be inside a\n",
    "      single visit, per feature. For example, if this is set to 50, then we are\n",
    "      assuming there can be up to 50 diagnosis codes, 50 treatment codes, and 50\n",
    "      lab codes. This will be used for creating the prior matrix.\n",
    "    prior_scalar: A float value between 0.0 and 1.0 to be used to hard-code the\n",
    "      diagnoal elements of the prior matrix.\n",
    "\n",
    "  Returns:\n",
    "    guide: The guide matrix.\n",
    "    prior_guide: The conditional probablity matrix.\n",
    "  \"\"\"\n",
    "  dx_ids = features['dx_ints']\n",
    "  proc_ids = features['proc_ints']\n",
    "  lab_ids = features['loinc_bucketized_ints']\n",
    "\n",
    "  batch_size = dx_ids.dense_shape[0]\n",
    "  num_dx_ids = max_num_codes if use_prior else dx_ids.dense_shape[-1]\n",
    "  num_proc_ids = max_num_codes if use_prior else proc_ids.dense_shape[-1]\n",
    "  num_lab_ids = max_num_codes if use_prior else lab_ids.dense_shape[-1]\n",
    "  num_codes = 1 + num_dx_ids + num_proc_ids + num_lab_ids\n",
    "\n",
    "  guide = None\n",
    "  if use_inf_mask:\n",
    "    row0 = tf.concat([\n",
    "        tf.zeros([1, 1]),\n",
    "        tf.ones([1, num_dx_ids]),\n",
    "        tf.zeros([1, num_proc_ids + num_lab_ids])\n",
    "    ],\n",
    "                     axis=1)\n",
    "\n",
    "    row1 = tf.concat([\n",
    "        tf.zeros([num_dx_ids, 1 + num_dx_ids]),\n",
    "        tf.ones([num_dx_ids, num_proc_ids]),\n",
    "        tf.zeros([num_dx_ids, num_lab_ids])\n",
    "    ],\n",
    "                     axis=1)\n",
    "\n",
    "    row2 = tf.concat([\n",
    "        tf.zeros([num_proc_ids, 1 + num_dx_ids + num_proc_ids]),\n",
    "        tf.ones([num_proc_ids, num_lab_ids])\n",
    "    ],\n",
    "                     axis=1)\n",
    "\n",
    "    row3 = tf.zeros([num_lab_ids, num_codes])\n",
    "\n",
    "    guide = tf.concat([row0, row1, row2, row3], axis=0)\n",
    "    guide = guide + tf.transpose(guide)\n",
    "    guide = tf.tile(guide[None, :, :], [batch_size, 1, 1])\n",
    "    guide = (\n",
    "        guide * mask[:, :, None] * mask[:, None, :] +\n",
    "        tf.eye(num_codes)[None, :, :])\n",
    "\n",
    "  prior_guide = None\n",
    "  if use_prior:\n",
    "    prior_values = features['prior_values']\n",
    "    prior_idx_values = prior_values.values\n",
    "\n",
    "    prior_indices = features['prior_indices']\n",
    "    prior_batch_idx = prior_indices.indices[:, 0][::2]\n",
    "    prior_idx = tf.reshape(prior_indices.values, [-1, 2])\n",
    "    prior_idx = tf.concat(\n",
    "        [prior_batch_idx[:, None], prior_idx[:, :1], prior_idx[:, 1:]], axis=1)\n",
    "\n",
    "    temp_idx = (\n",
    "        prior_idx[:, 0] * 1000000 + prior_idx[:, 1] * 1000 + prior_idx[:, 2])\n",
    "    sorted_idx = tf.contrib.framework.argsort(temp_idx)\n",
    "    prior_idx = tf.gather(prior_idx, sorted_idx)\n",
    "\n",
    "    prior_idx_shape = [batch_size, max_num_codes * 3, max_num_codes * 3]\n",
    "    sparse_prior = tf.SparseTensor(\n",
    "        indices=prior_idx, values=prior_idx_values, dense_shape=prior_idx_shape)\n",
    "    prior_guide = tf.sparse.to_dense(sparse_prior, validate_indices=True)\n",
    "\n",
    "    visit_guide = tf.convert_to_tensor(\n",
    "        [prior_scalar] * max_num_codes + [0.0] * max_num_codes * 2,\n",
    "        dtype=tf.float32)\n",
    "    prior_guide = tf.concat(\n",
    "        [tf.tile(visit_guide[None, None, :], [batch_size, 1, 1]), prior_guide],\n",
    "        axis=1)\n",
    "    visit_guide = tf.concat([[0.0], visit_guide], axis=0)\n",
    "    prior_guide = tf.concat(\n",
    "        [tf.tile(visit_guide[None, :, None], [batch_size, 1, 1]), prior_guide],\n",
    "        axis=2)\n",
    "    prior_guide = (\n",
    "        prior_guide * mask[:, :, None] * mask[:, None, :] +\n",
    "        prior_scalar * tf.eye(num_codes)[None, :, :])\n",
    "    degrees = tf.reduce_sum(prior_guide, axis=2)\n",
    "    prior_guide = prior_guide / degrees[:, :, None]\n",
    "\n",
    "  return guide, prior_guide\n",
    "\n",
    "\n",
    "def create_matrix_vdp(features, mask, use_prior, use_inf_mask, max_num_codes,\n",
    "                      prior_scalar):\n",
    "  \"\"\"Creates guide matrix and prior matrix when feature_set='vdp'.\n",
    "\n",
    "  This function creates the guide matrix and the prior matrix when visits\n",
    "  include diagnosis codes, treatment codes, but not lab codes.\n",
    "\n",
    "  Args:\n",
    "    features: A dictionary of SparseTensors for each feature.\n",
    "    mask: 3D float Tensor of size (batch_size, num_features, 1). This holds\n",
    "      binary values to indicate which parts are padded and which are not.\n",
    "    use_prior: Whether to create the prior matrix.\n",
    "    use_inf_mask : Whether to create the guide matrix.\n",
    "    max_num_codes: The maximum number of how many feature there can be inside a\n",
    "      single visit, per feature. For example, if this is set to 50, then we are\n",
    "      assuming there can be up to 50 diagnosis codes and 50 treatment codes.\n",
    "      This will be used for creating the prior matrix.\n",
    "    prior_scalar: A float value between 0.0 and 1.0 to be used to hard-code the\n",
    "      diagnoal elements of the prior matrix.\n",
    "\n",
    "  Returns:\n",
    "    guide: The guide matrix.\n",
    "    prior_guide: The conditional probablity matrix.\n",
    "  \"\"\"\n",
    "  dx_ids = features['dx_ints']\n",
    "  proc_ids = features['proc_ints']\n",
    "\n",
    "  batch_size = dx_ids.dense_shape[0]\n",
    "  num_dx_ids = max_num_codes if use_prior else dx_ids.dense_shape[-1]\n",
    "  num_proc_ids = max_num_codes if use_prior else proc_ids.dense_shape[-1]\n",
    "  num_codes = 1 + num_dx_ids + num_proc_ids\n",
    "\n",
    "  guide = None\n",
    "  if use_inf_mask:\n",
    "    row0 = tf.concat([\n",
    "        tf.zeros([1, 1]),\n",
    "        tf.ones([1, num_dx_ids]),\n",
    "        tf.zeros([1, num_proc_ids])\n",
    "    ],\n",
    "                     axis=1)\n",
    "\n",
    "    row1 = tf.concat([\n",
    "        tf.zeros([num_dx_ids, 1 + num_dx_ids]),\n",
    "        tf.ones([num_dx_ids, num_proc_ids])\n",
    "    ],\n",
    "                     axis=1)\n",
    "\n",
    "    row2 = tf.zeros([num_proc_ids, num_codes])\n",
    "\n",
    "    guide = tf.concat([row0, row1, row2], axis=0)\n",
    "    guide = guide + tf.transpose(guide)\n",
    "    guide = tf.tile(guide[None, :, :], [batch_size, 1, 1])\n",
    "    guide = (\n",
    "        guide * mask[:, :, None] * mask[:, None, :] +\n",
    "        tf.eye(num_codes)[None, :, :])\n",
    "\n",
    "  prior_guide = None\n",
    "  if use_prior:\n",
    "    prior_values = features['prior_values']\n",
    "    prior_idx_values = prior_values.values\n",
    "\n",
    "    prior_indices = features['prior_indices']\n",
    "    prior_batch_idx = prior_indices.indices[:, 0][::2]\n",
    "    prior_idx = tf.reshape(prior_indices.values, [-1, 2])\n",
    "    prior_idx = tf.concat(\n",
    "        [prior_batch_idx[:, None], prior_idx[:, :1], prior_idx[:, 1:]], axis=1)\n",
    "\n",
    "    temp_idx = (\n",
    "        prior_idx[:, 0] * 1000000 + prior_idx[:, 1] * 1000 + prior_idx[:, 2])\n",
    "    sorted_idx = tf.contrib.framework.argsort(temp_idx)\n",
    "    prior_idx = tf.gather(prior_idx, sorted_idx)\n",
    "\n",
    "    prior_idx_shape = [batch_size, max_num_codes * 2, max_num_codes * 2]\n",
    "    sparse_prior = tf.SparseTensor(\n",
    "        indices=prior_idx, values=prior_idx_values, dense_shape=prior_idx_shape)\n",
    "    prior_guide = tf.sparse.to_dense(sparse_prior, validate_indices=True)\n",
    "\n",
    "    visit_guide = tf.convert_to_tensor(\n",
    "        [prior_scalar] * max_num_codes + [0.0] * max_num_codes * 1,\n",
    "        dtype=tf.float32)\n",
    "    prior_guide = tf.concat(\n",
    "        [tf.tile(visit_guide[None, None, :], [batch_size, 1, 1]), prior_guide],\n",
    "        axis=1)\n",
    "    visit_guide = tf.concat([[0.0], visit_guide], axis=0)\n",
    "    prior_guide = tf.concat(\n",
    "        [tf.tile(visit_guide[None, :, None], [batch_size, 1, 1]), prior_guide],\n",
    "        axis=2)\n",
    "    prior_guide = (\n",
    "        prior_guide * mask[:, :, None] * mask[:, None, :] +\n",
    "        prior_scalar * tf.eye(num_codes)[None, :, :])\n",
    "    degrees = tf.reduce_sum(prior_guide, axis=2)\n",
    "    prior_guide = prior_guide / degrees[:, :, None]\n",
    "\n",
    "  return guide, prior_guide\n",
    "\n",
    "\n",
    "class SequenceExampleParser(object):\n",
    "  \"\"\"A very simple SequenceExample parser for eICU data.\n",
    "\n",
    "  This Parser class is intended to be used for eICU SequenceExamples obtained\n",
    "  from process_eicu.py. This class will not work with synthetic samples obtained\n",
    "  from process_synthetic.py, because synthetic samples contain a different set\n",
    "  of features and labels than eICU samples.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, batch_size, num_map_threads=4):\n",
    "    \"\"\"Init function.\"\"\"\n",
    "    self.context_features_config = {\n",
    "        'patientId': tf.io.RaggedFeature(tf.string),\n",
    "        'label.readmission': tf.io.FixedLenFeature([1], tf.int64),\n",
    "        'label.expired': tf.io.FixedLenFeature([1], tf.int64)\n",
    "    }\n",
    "\n",
    "    self.sequence_features_config = {\n",
    "        'dx_ints': tf.io.RaggedFeature(tf.int64),\n",
    "        'proc_ints': tf.io.RaggedFeature(tf.int64),\n",
    "        'prior_indices': tf.io.RaggedFeature(tf.int64),\n",
    "        'prior_values': tf.io.RaggedFeature(tf.float32)\n",
    "    }\n",
    "\n",
    "    self.batch_size = batch_size\n",
    "    self.num_map_threads = num_map_threads\n",
    "\n",
    "  def __call__(self, tfrecord_path, label_key, training):\n",
    "    \"\"\"Parse function.\n",
    "\n",
    "    Args:\n",
    "      tfrecord_path: Path to TFRecord of SequenceExamples.\n",
    "      training: Boolean value to indicate whether the model if training.\n",
    "\n",
    "    Returns:\n",
    "      Dataset iterator.\n",
    "    \"\"\"\n",
    "\n",
    "    def parser_fn(serialized_example):\n",
    "      (batch_context, batch_sequence) = tf.io.parse_single_sequence_example(\n",
    "          serialized_example,\n",
    "          context_features=self.context_features_config,\n",
    "          sequence_features=self.sequence_features_config)\n",
    "      labels = tf.squeeze(tf.cast(batch_context[label_key], tf.float32))\n",
    "      return batch_sequence, labels\n",
    "\n",
    "    num_epochs = None if training else 1\n",
    "    buffer_size = self.batch_size * 32\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.map(parser_fn, num_parallel_calls=self.num_map_threads)\n",
    "    dataset = dataset.batch(self.batch_size)\n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "\n",
    "class EHRTransformer(object):\n",
    "  \"\"\"Transformer-based EHR encounter modeling algorithm.\n",
    "\n",
    "  All features within each encounter are put through multiple steps of\n",
    "  self-attention. There is a dummy visit embedding in addition to other\n",
    "  feature embeddings, which can be used for encounter-level predictions.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               gct_params,\n",
    "               feature_keys=['dx_ints', 'proc_ints'],\n",
    "               label_key='label.readmission',\n",
    "               vocab_sizes={'dx_ints':3249, 'proc_ints':2210},\n",
    "               feature_set='vdp',\n",
    "               max_num_codes=50,\n",
    "               prior_scalar=0.5,\n",
    "               reg_coef=0.1,\n",
    "               num_classes=1,\n",
    "               learning_rate=1e-3,\n",
    "               batch_size=32):\n",
    "    \"\"\"Init function.\n",
    "\n",
    "    Args:\n",
    "      gct_params: A dictionary parameteres to be used inside GCT class. See GCT\n",
    "        comments for more information.\n",
    "      feature_keys: A list of feature names you want to use. (e.g. ['dx_ints,\n",
    "        'proc_ints', 'lab_ints'])\n",
    "      vocab_sizes: A dictionary of vocabularize sizes for each feature. (e.g.\n",
    "        {'dx_ints': 1001, 'proc_ints': 1001, 'lab_ints': 1001})\n",
    "      feature_set: Use 'vdpl' to indicate your features are diagnosis codes,\n",
    "        treatment codes, and lab codes. Use 'vdp' to indicate your features are\n",
    "        diagnosis codes and treatment codes.\n",
    "      max_num_codes: The maximum number of how many feature there can be inside\n",
    "        a single visit, per feature. For example, if this is set to 50, then we\n",
    "        are assuming there can be up to 50 diagnosis codes, 50 treatment codes,\n",
    "        and 50 lab codes. This will be used for creating the prior matrix.\n",
    "      prior_scalar: A float value between 0.0 and 1.0 to be used to hard-code\n",
    "        the diagnoal elements of the prior matrix.\n",
    "      reg_coef: A coefficient to decide the KL regularization balance when\n",
    "        training GCT.\n",
    "      num_classes: This is set to 1, because this implementation only supports\n",
    "        graph-level binary classification.\n",
    "      learning_rate: Learning rate for Adam optimizer.\n",
    "      batch_size: Batch size.\n",
    "    \"\"\"\n",
    "    self._feature_keys = feature_keys\n",
    "    self._label_key = label_key\n",
    "    self._vocab_sizes = vocab_sizes\n",
    "    self._feature_set = feature_set\n",
    "    self._max_num_codes = max_num_codes\n",
    "    self._prior_scalar = prior_scalar\n",
    "    self._reg_coef = reg_coef\n",
    "    self._num_classes = num_classes\n",
    "    self._learning_rate = learning_rate\n",
    "    self._batch_size = batch_size\n",
    "\n",
    "    self._gct_params = gct_params\n",
    "    self._embedding_size = gct_params['embedding_size']\n",
    "    self._num_transformer_stack = gct_params['num_transformer_stack']\n",
    "    self._use_inf_mask = gct_params['use_inf_mask']\n",
    "    self._use_prior = gct_params['use_prior']\n",
    "\n",
    "    self._seqex_reader = SequenceExampleParser(self._batch_size)\n",
    "\n",
    "  def get_prediction(self, model, feature_embedder, features, training=False):\n",
    "    \"\"\"Accepts features and produces logits and attention values.\n",
    "\n",
    "    Args:\n",
    "      features: A dictionary of SparseTensors for each sequence feature.\n",
    "      training: A boolean value to indicate whether the predictions are for\n",
    "        training or inference. If set to True, dropouts will take effect.\n",
    "\n",
    "    Returns:\n",
    "      logits: Logits for prediction.\n",
    "      attentions: List of attention values from all layers of GCT. Pass this to\n",
    "        get_loss to regularize the attention generation mechanism.\n",
    "    \"\"\"\n",
    "    # 1. Embedding lookup\n",
    "    embedding_dict, mask_dict = feature_embedder.lookup(\n",
    "        features, self._max_num_codes)\n",
    "\n",
    "    # 2. Concatenate embeddings and masks into a single tensor.\n",
    "    keys = ['visit'] + self._feature_keys\n",
    "    embeddings = tf.concat([embedding_dict[key] for key in keys], axis=1)\n",
    "    masks = tf.concat([mask_dict[key] for key in keys], axis=1)\n",
    "\n",
    "    # 2-1. Create the guide matrix and the prior matrix.\n",
    "    if self._feature_set == 'vdpl':\n",
    "      guide, prior_guide = create_matrix_vdpl(features, masks, self._use_prior,\n",
    "                                              self._use_inf_mask,\n",
    "                                              self._max_num_codes,\n",
    "                                              self._prior_scalar)\n",
    "    elif self._feature_set == 'vdp':\n",
    "      guide, prior_guide = create_matrix_vdp(features, masks, self._use_prior,\n",
    "                                             self._use_inf_mask,\n",
    "                                             self._max_num_codes,\n",
    "                                             self._prior_scalar)\n",
    "    else:\n",
    "      sys.exit(0)\n",
    "\n",
    "    # 3. Process embeddings with GCT\n",
    "    hidden, attentions = model(\n",
    "        embeddings, masks[:, :, None], guide, prior_guide, training)\n",
    "\n",
    "    # 4. Generate logits\n",
    "    pre_logit = hidden[:, 0, :]\n",
    "    pre_logit = tf.reshape(pre_logit, [-1, self._embedding_size])\n",
    "    logits = tf.layers.dense(pre_logit, self._num_classes, activation=None)\n",
    "    logits = tf.squeeze(logits)\n",
    "\n",
    "    return logits, attentions\n",
    "\n",
    "  def get_loss(self, logits, labels, attentions):\n",
    "    \"\"\"Creates a loss tensor.\n",
    "\n",
    "    Args:\n",
    "      logits: Logits for prediction. This is obtained by calling get_prediction.\n",
    "      labels: Labels for prediction.\n",
    "      attentions: List of attention values from all layers of GCT. This is\n",
    "        obtained by calling get_prediction.\n",
    "\n",
    "    Returns:\n",
    "      Loss tensor. If we use the conditional probability matrix, then GCT's\n",
    "      attention mechanism will be regularized using KL divergence.\n",
    "    \"\"\"\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "\n",
    "    if self._use_prior:\n",
    "      kl_terms = []\n",
    "      attention_tensor = tf.convert_to_tensor(attentions)\n",
    "      for i in range(1, self._num_transformer_stack):\n",
    "        log_p = tf.log(attention_tensor[i - 1] + 1e-12)\n",
    "        log_q = tf.log(attention_tensor[i] + 1e-12)\n",
    "        kl_term = attention_tensor[i - 1] * (log_p - log_q)\n",
    "        kl_term = tf.reduce_sum(kl_term, axis=-1)\n",
    "        kl_term = tf.reduce_mean(kl_term)\n",
    "        kl_terms.append(kl_term)\n",
    "\n",
    "      reg_term = tf.reduce_mean(kl_terms)\n",
    "      loss += self._reg_coef * reg_term\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def input_fn(self, tfrecord_path, training):\n",
    "    \"\"\"Input function to be used by TensorFlow Estimator.\n",
    "\n",
    "    Args:\n",
    "      tfrecord_path: Path to TFRecord of SequenceExamples.\n",
    "      training: Boolean value to indicate whether the model if training.\n",
    "\n",
    "    Return:\n",
    "      Input generator.\n",
    "    \"\"\"\n",
    "    return self._seqex_reader(tfrecord_path, self._label_key, training)\n",
    "\n",
    "  def model_fn(self, features, labels, mode):\n",
    "    \"\"\"Model function to be used by TensorFlow Estimator.\n",
    "\n",
    "    Args:\n",
    "      features: Dictionary of features.\n",
    "      labels: True labels for training.\n",
    "      mode: The mode the model is in tf.estimator.ModeKeys.\n",
    "\n",
    "    Return:\n",
    "      Train/Eval/Prediction op depending on the mode.\n",
    "    \"\"\"\n",
    "    training = mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "    model = GraphConvolutionalTransformer(**self._gct_params)\n",
    "    feature_embedder = FeatureEmbedder(\n",
    "        self._vocab_sizes, self._feature_keys, self._embedding_size)\n",
    "\n",
    "    logits, attentions = self.get_prediction(\n",
    "        model, feature_embedder, features, training)\n",
    "    probs = tf.nn.sigmoid(logits)\n",
    "    predictions = {\n",
    "        'probabilities': probs,\n",
    "        'logits': logits,\n",
    "    }\n",
    "\n",
    "    # output predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # create loss (should be equal to caffe softmaxwithloss)\n",
    "    loss = self.get_loss(logits, labels, attentions)\n",
    "\n",
    "    if training:\n",
    "      optimizer = tf.train.AdamOptimizer(learning_rate=self._learning_rate,\n",
    "                                         beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "      train_op = optimizer.minimize(loss)\n",
    "      global_step = tf.train.get_global_step()\n",
    "      update_global_step = tf.assign(\n",
    "          global_step, global_step+1, name='update_global_step')\n",
    "\n",
    "      # create estimator training spec.\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode,\n",
    "          loss=loss,\n",
    "          train_op=tf.group(train_op, update_global_step),\n",
    "          predictions=predictions)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "      # Define the metrics:\n",
    "      metrics_dict = {\n",
    "          'AUC-PR': tf.metrics.auc(labels, probs, curve='PR',\n",
    "                                   summation_method='careful_interpolation'),\n",
    "          'AUC-ROC': tf.metrics.auc(labels, probs, curve='ROC',\n",
    "                                 summation_method='careful_interpolation')\n",
    "      }\n",
    "\n",
    "      #return eval spec\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode, loss=loss, eval_metric_ops=metrics_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Finally, we train the model. This model will train with 100,000 iterations to ensure accuracy. It is trained using TensorFlow Estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Copyright 2019 Google LLC.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    https://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import graph_convolutional_transformer as gct\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "  gct_params = {\n",
    "      \"embedding_size\": 128,\n",
    "      \"num_transformer_stack\": 3,\n",
    "      \"num_feedforward\": 2,\n",
    "      \"num_attention_heads\": 1,\n",
    "      \"ffn_dropout\": 0.08,\n",
    "      \"attention_normalizer\": \"softmax\",\n",
    "      \"multihead_attention_aggregation\": \"concat\",\n",
    "      \"directed_attention\": False,\n",
    "      \"use_inf_mask\": True,\n",
    "      \"use_prior\": True,\n",
    "  }\n",
    "\n",
    "  input_path = argv[1]\n",
    "  model_dir = argv[2]\n",
    "  num_iter = 1000000\n",
    "  model = gct.EHRTransformer(\n",
    "      gct_params=gct_params,\n",
    "      label_key='label.readmission',\n",
    "      reg_coef=0.1,\n",
    "      learning_rate=0.00022,\n",
    "      batch_size=32)\n",
    "  config = tf.estimator.RunConfig(save_checkpoints_steps=100)\n",
    "\n",
    "  estimator = tf.estimator.Estimator(\n",
    "      model_dir=model_dir, model_fn=model.model_fn, config=config)\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "      input_fn=lambda: model.input_fn(input_path + './train.tfrecord', True),\n",
    "      max_steps=num_iter)\n",
    "\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "      input_fn=lambda: model.input_fn(input_path + './validation.tfrecord', False),\n",
    "      throttle_secs=1)\n",
    "\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "  estimator.evaluate(\n",
    "      input_fn=lambda: model.input_fn(input_path + './validation.tfrecord', False))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  tf.app.run(main)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The metrics that are produced from training the GCT model are the validation accuracy, test accuracy, validation AUCPR, and test AUCPR.\n",
    "\n",
    "Accuracy: How often the model predicted the true result\n",
    "AUCPR: Area Under the Precision-Recall - Precision being the ratio between the true positive predictions and the total number of positive predictions, and Recal being the ratio of true positive predictions with the total number of actual positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "models = ['GCN_p', 'GNC_r', 'Shallow', 'Deep', 'Transformer', 'GCT']\n",
    "validation_aucpr = [0.844, 0.784, 0.853, 0.821, 0.833, 0.869]\n",
    "test_aucpr = [0.844, 0.78, 0.856, 0.82, 0.838, 0.867]\n",
    "validation_acc = [0.7343, 0.713, 0.731, 0.719, 0.77, 0.731]\n",
    "test_acc = [0.743, 0.719, 0.736, 0.734, 0.717, 0.770]\n",
    "\n",
    "# Plotting AUCPR\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "plt.bar(index, validation_aucpr, bar_width, label='Validation', color='b')\n",
    "plt.bar(index + bar_width, test_aucpr, bar_width, label='Test', color='r')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('AUCPR')\n",
    "plt.title('AUCPR Comparison - Validation vs Test')\n",
    "plt.xticks(index + bar_width/2, models)\n",
    "plt.legend()\n",
    "\n",
    "# Plotting ACC\n",
    "plt.subplot(1, 2, 2)\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "plt.bar(index, validation_acc, bar_width, label='Validation', color='b')\n",
    "plt.bar(index + bar_width, test_acc, bar_width, label='Test', color='r')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Comparison - Validation vs Test')\n",
    "plt.xticks(index + bar_width/2, models)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results, Analysis, Plans\n",
    "\n",
    "As we can see, on all accounts we can see that the GCT (Graph Convolutional Transformer) has performed better in comparison to the other model types with respect to accuracy and AUCPR.\n",
    "\n",
    "The data shows that the GCT model, when compared to the other models, specifically GCN & Transformer, is clearly better in its performance. This proves that the conditional probability in the tree like structure of the EHR data is indeed hidden information being missed by the previously used models depicted in the data.\n",
    "\n",
    "In regards to the accuracy of the eICU, the GCN's performance could not be assessed in the eICU dataset because of the absence of its true structure. If we look at the Transformer model, we can see a similar performance to a randomly structured GCN. This is surprising as it indicates a different challenge compared to tasks like graph reconstruction. The GCT ends up performing the best yet again. This is due to the fact that many of the entries, about 80 percent of them, have the codes that allow for the model to know whether or not a patient was in the operating room previously. This makes it easier for the model to predict the mortality.\n",
    "\n",
    "Our plan with this model is to continually fine tune it by adjusting the different hyperparams, such as the learning rate, number of epochs, batch size, number of hidden layers, activators, optimizers, and adding dropout.By adjusting these parameters perhaps we can see whether with certain data this model will perform better than already seen in this study. We will also test with different subsets of data to see if we can train the model more directly with specific data types, and adjust the hyperparameters accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
